templates:
  postfix: ""
output_dir: "runs/instance-p3-lamma2/vanilla_bg100{postfix}"
model_name: "meta-llama/Llama-2-7b-chat-hf"

cl_method: "vanilla"
cand_k: 100

replay_freq: -1

max_bg_per_task: 100

use_eval_mode: true

is_seq2seq: false
is_llama: true

max_output_length: 64

max_input_length: 512
per_device_eval_batch_size: 8